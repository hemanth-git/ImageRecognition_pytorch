{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using pytorch\n",
    "linear regression + logistic function(softmax) = logistic regression\n",
    "\n",
    "### Steps for Logistic regression\n",
    "A. Preparing the Data set\n",
    "1. Import libraries\n",
    "2. We use MNIST dataset.\n",
    "3. There are 28*28 images and 10 labels from 0 to 9\n",
    "4. Data is not normalized so we divide each image to 255 that is basic normalization for images.\n",
    "5. use train_test_split method from sklearn library\n",
    "6. Create feature and target tensors\n",
    "7. epoch: 1 epoch means training all samples one time.\n",
    "8. batch_size = batch size means is that for example we have data and it includes 1000 sample. We can train 1000 sample in a     same time or we can divide it 10 groups which include 100 sample and train 10 groups in order. Batch size is the group size. For example, I choose batch_size = 100, that means in order to train all data only once we have 336 groups. We train each groups(336) that have batch_size(quota) 100. Finally we train 33600 sample one time.\n",
    "9. Therefore, 1 epoch(training data only once) takes 336 iteration\n",
    "10. TensorDataset(): Data set wrapping tensors. Each sample is retrieved by indexing tensors along the first dimension.\n",
    "11. DataLoader(): It combines dataset and sampler. It also provides multi process iterators over the dataset.\n",
    "\n",
    "B. Creating the Logistic model\n",
    "\n",
    "C. Instantiate Model class\n",
    "\n",
    "    input_dim = 28,28 # size of image px,px\n",
    "    output_dim = 10 # labels 0,1,2,3,4,5,6,7,8,9\n",
    "    create model\n",
    "\n",
    "D. Instantiate Loss class\n",
    "\n",
    "    Cross entropy loss\n",
    "    It calculates loss that is not surprise :)\n",
    "    It also has softmax(logistic function) in it.\n",
    "\n",
    "E. Instantiate optimizer class\n",
    "    SGD Optimizer\n",
    "\n",
    "F. Traning the Model\n",
    "\n",
    "G. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "train=pd.read_csv(\"D:\\\\Data Science\\\\DeepLearning\\\\all\\\\train.csv\",dtype = np.float32)\n",
    "\n",
    "#splitting the data in to features(X) and labels(Y)\n",
    "\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the numpy data frame to features and target Tensors\n",
    "\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size and iterations\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600,\n",
       " (42000, 785),\n",
       " Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
       "        'pixel6', 'pixel7', 'pixel8',\n",
       "        ...\n",
       "        'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "        'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "       dtype='object', length=785))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train), train.shape, train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Dataset and Tensor data loader\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample visualization of single data point\n",
    "# using numpy data point\n",
    "plt.imshow(features_numpy[11].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemanth\\Anaconda3\\lib\\site-packages\\torch\\tensor.py:287: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using the Tensor featuresTrain to visualise the data point\n",
    "plt.imshow(featuresTrain[11].resize(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Logistic model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_dim,output_dim)\n",
    "        # Logistic function is implemented at loss function or inbulit so will implement there\n",
    "    def forward(self,x):\n",
    "        out=self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=28*28\n",
    "output_dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "model= LogisticRegressionModel(input_dim,output_dim)\n",
    "error= nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.822788953781128  Accuracy: 67%\n",
      "Iteration: 1000  Loss: 1.592555284500122  Accuracy: 74%\n",
      "Iteration: 1500  Loss: 1.2994662523269653  Accuracy: 78%\n",
      "Iteration: 2000  Loss: 1.2022182941436768  Accuracy: 79%\n",
      "Iteration: 2500  Loss: 1.0183779001235962  Accuracy: 81%\n",
      "Iteration: 3000  Loss: 0.9255053997039795  Accuracy: 81%\n",
      "Iteration: 3500  Loss: 0.8991302251815796  Accuracy: 82%\n",
      "Iteration: 4000  Loss: 0.7588906288146973  Accuracy: 83%\n",
      "Iteration: 4500  Loss: 0.9758384823799133  Accuracy: 83%\n",
      "Iteration: 5000  Loss: 0.7925894856452942  Accuracy: 84%\n",
      "Iteration: 5500  Loss: 0.7547786831855774  Accuracy: 84%\n",
      "Iteration: 6000  Loss: 0.8685271739959717  Accuracy: 84%\n",
      "Iteration: 6500  Loss: 0.6683892607688904  Accuracy: 84%\n",
      "Iteration: 7000  Loss: 0.7118467688560486  Accuracy: 85%\n",
      "Iteration: 7500  Loss: 0.6340833306312561  Accuracy: 85%\n",
      "Iteration: 8000  Loss: 0.7346197366714478  Accuracy: 85%\n",
      "Iteration: 8500  Loss: 0.5471299886703491  Accuracy: 85%\n",
      "Iteration: 9000  Loss: 0.6577434539794922  Accuracy: 85%\n",
      "Iteration: 9500  Loss: 0.5217925906181335  Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model with Test data set \n",
    "\n",
    "#### before proceding with test we need to normalize and prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "testsample=pd.read_csv(\"D:\\\\Data Science\\\\DeepLearning\\\\all\\\\test.csv\",dtype = np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#splitting the data in to features(X) and labels(Y)\n",
    "\n",
    "features_numpy_test = testsample.loc[:,train.columns != \"label\"].values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy to Tensor\n",
    "\n",
    "features_tensor_test = torch.from_numpy(features_numpy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = model(features_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = torch.max(output_test.data, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_predicted=predicted_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(numpy_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {0:'Label'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(1,28001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.rename(columns={0:'ImageId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Label']=pd.Series(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Submission_format.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
